name: Nuclei Mass Vulnerability Scan

on:
  workflow_dispatch:
    inputs:
      batch_start:
        description: 'Starting batch number'
        required: true
        default: '1'
        type: string
      batch_end:
        description: 'Ending batch number'
        required: true
        default: '10'
        type: string
      scan_profile:
        description: 'Scan profile (quick/full/critical)'
        required: true
        default: 'full'
        type: choice
        options:
        - quick
        - full
        - critical
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  BATCH_SIZE: 1  # Reduced batch size for faster completion
  MAX_PARALLEL_JOBS: 15  # Conservative limit to avoid GitHub rate limits
  NUCLEI_VERSION: "v3.1.0"
  RESULTS_BRANCH: "scan-results"  # Dedicated branch for storing results

jobs:
  # Job to generate batch matrix
  prepare-batches:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.generate-matrix.outputs.matrix }}
      total_batches: ${{ steps.generate-matrix.outputs.total_batches }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup GPG for decryption
        run: |
          # Import GPG keys
          echo "${{ secrets.GPG_PRIVATE_KEY }}" | gpg --batch --import
          echo "${{ secrets.GPG_PUBLIC_KEY }}" | gpg --batch --import
          
          # Verify GPG setup
          gpg --list-secret-keys --keyid-format LONG
          echo "âœ… GPG keys imported successfully"

      - name: Decrypt subdomain file
        run: |
          if [ -f "subdomains/all-subdomains.txt.gpg" ]; then
            # Decrypt with trust model override
            gpg --batch --yes --quiet --trust-model always --decrypt "subdomains/all-subdomains.txt.gpg" > "subdomains/all-subdomains.txt"
            
            # Verify decryption worked
            if [ -s "subdomains/all-subdomains.txt" ]; then
              LINES=$(wc -l < "subdomains/all-subdomains.txt")
              echo "âœ… Subdomain file decrypted successfully - $LINES lines"
            else
              echo "âŒ Decryption failed - output file is empty"
              exit 1
            fi
          else
            echo "âŒ Error: subdomains/all-subdomains.txt.gpg not found"
            echo "Please encrypt your subdomain file using: gpg --encrypt --armor --recipient \$GPG_KEY_ID subdomains/all-subdomains.txt"
            exit 1
          fi

      - name: Generate batch matrix
        id: generate-matrix
        run: |
          # Count total subdomains
          if [ -f "subdomains/all-subdomains.txt" ]; then
            TOTAL_SUBDOMAINS=$(wc -l < subdomains/all-subdomains.txt)
          else
            echo "Error: subdomains/all-subdomains.txt not found after decryption"
            exit 1
          fi
          
          # Calculate total batches needed
          TOTAL_BATCHES=$(( (TOTAL_SUBDOMAINS + BATCH_SIZE - 1) / BATCH_SIZE ))
          
          # Set batch range based on input or default
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            START_BATCH=${{ github.event.inputs.batch_start }}
            END_BATCH=${{ github.event.inputs.batch_end }}
          else
            # For scheduled runs, process all batches in chunks
            START_BATCH=1
            END_BATCH=$(( TOTAL_BATCHES > MAX_PARALLEL_JOBS ? MAX_PARALLEL_JOBS : TOTAL_BATCHES ))
          fi
          
          # Generate matrix
          MATRIX="["
          for i in $(seq $START_BATCH $END_BATCH); do
            if [ $i -le $TOTAL_BATCHES ]; then
              MATRIX="${MATRIX}${i},"
            fi
          done
          MATRIX="${MATRIX%,}]"
          
          echo "matrix=${MATRIX}" >> $GITHUB_OUTPUT
          echo "total_batches=${TOTAL_BATCHES}" >> $GITHUB_OUTPUT
          
          echo "Generated matrix for batches ${START_BATCH}-${END_BATCH} of ${TOTAL_BATCHES} total batches"
          echo "Total subdomains: ${TOTAL_SUBDOMAINS}"

  # Main scanning job with matrix strategy
  nuclei-scan:
    needs: prepare-batches
    if: needs.prepare-batches.outputs.matrix != '[]'
    runs-on: ubuntu-latest
    timeout-minutes: 300  # 5h to allow buffer for cleanup
    strategy:
      fail-fast: false
      max-parallel: 15  # Conservative limit to avoid GitHub rate limits
      matrix:
        batch: ${{ fromJson(needs.prepare-batches.outputs.matrix) }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup GPG for decryption
        run: |
          # Import GPG keys
          echo "${{ secrets.GPG_PRIVATE_KEY }}" | gpg --batch --import
          echo "${{ secrets.GPG_PUBLIC_KEY }}" | gpg --batch --import
          
          # Verify GPG setup
          gpg --list-secret-keys --keyid-format LONG
          echo "âœ… GPG keys imported successfully"

      - name: Decrypt subdomain file
        run: |
          if [ -f "subdomains/all-subdomains.txt.gpg" ]; then
            gpg --batch --yes --quiet --trust-model always --decrypt "subdomains/all-subdomains.txt.gpg" > "subdomains/all-subdomains.txt"
            echo "Subdomain file decrypted successfully"
          else
            echo "Error: subdomains/all-subdomains.txt.gpg not found"
            exit 1
          fi

      - name: Setup Go
        uses: actions/setup-go@v4
        with:
          go-version: '1.21'

      - name: Install Nuclei
        run: |
          go install -v github.com/projectdiscovery/nuclei/v3/cmd/nuclei@${{ env.NUCLEI_VERSION }}
          nuclei -version

      - name: Update Nuclei templates
        run: |
          # Update templates and show where they're stored
          nuclei -update-templates
          
          # Check both possible locations
          echo "ðŸ” Checking template locations..."
          for template_dir in ~/nuclei-templates ; do
            if [ -d "$template_dir" ]; then
              TEMPLATE_COUNT=$(find "$template_dir" -name "*.yaml" -o -name "*.yml" 2>/dev/null | wc -l)
              echo "ðŸ“ Found $TEMPLATE_COUNT templates at: $template_dir"
              ls -la "$template_dir" | head -5
              echo "NUCLEI_TEMPLATES_PATH=$template_dir" >> $GITHUB_ENV
              break
            fi
          done
          
          # If still not found, check what nuclei created
          if [ -z "${NUCLEI_TEMPLATES_PATH:-}" ]; then
            echo "ðŸ” Searching for templates in common locations..."
            find /home/runner -name "*.yaml" -path "*/nuclei-templates/*" | head -5
            find ~ -name nuclei-templates -type d 2>/dev/null
          fi

      - name: Prepare subdomain batch
        id: prepare-batch
        run: |
          BATCH_NUM=${{ matrix.batch }}
          START_LINE=$(( (BATCH_NUM - 1) * BATCH_SIZE + 1 ))
          END_LINE=$(( BATCH_NUM * BATCH_SIZE ))
          
          # Extract batch from main file
          sed -n "${START_LINE},${END_LINE}p" subdomains/all-subdomains.txt > batch_${BATCH_NUM}.txt
          
          # Count actual subdomains in this batch
          ACTUAL_COUNT=$(wc -l < batch_${BATCH_NUM}.txt)
          
          echo "batch_file=batch_${BATCH_NUM}.txt" >> $GITHUB_OUTPUT
          echo "subdomain_count=${ACTUAL_COUNT}" >> $GITHUB_OUTPUT
          echo "Processing batch ${BATCH_NUM} with ${ACTUAL_COUNT} subdomains"

      - name: Configure scan parameters
        id: scan-config
        run: |
          PROFILE="${{ github.event.inputs.scan_profile || 'full' }}"
          
          # Use detected template path or default
          TEMPLATE_DIR="${NUCLEI_TEMPLATES_PATH:-~/nuclei-templates}"
          
          # Verify template directory exists
          if [ ! -d "$TEMPLATE_DIR" ]; then
            echo "âš ï¸ Template directory not found at $TEMPLATE_DIR, trying alternatives..."
            for alt_dir in ~/nuclei-templates /home/runner/nuclei-templates; do
              if [ -d "$alt_dir" ]; then
                TEMPLATE_DIR="$alt_dir"
                echo "âœ… Using template directory: $TEMPLATE_DIR"
                break
              fi
            done
          fi
          
          case $PROFILE in
            "quick")
              TEMPLATES="-t $TEMPLATE_DIR"
              SEVERITY="-severity info"
              RATE_LIMIT="-rl 1000"
              TIMEOUT="-timeout 3"
              ;;
            "critical")
              TEMPLATES="-t $TEMPLATE_DIR"
              SEVERITY="-severity critical"
              RATE_LIMIT="-rl 550"
              TIMEOUT="-timeout 5"
              ;;
            "full"|*)
              TEMPLATES="-t $TEMPLATE_DIR/"  # All templates
              SEVERITY="-severity critical,high,medium,low"
              RATE_LIMIT="-rl 550"
              TIMEOUT="-timeout 8"
              ;;
          esac
          
          echo "templates=${TEMPLATES}" >> $GITHUB_OUTPUT
          echo "severity=${SEVERITY}" >> $GITHUB_OUTPUT
          echo "rate_limit=${RATE_LIMIT}" >> $GITHUB_OUTPUT
          echo "timeout=${TIMEOUT}" >> $GITHUB_OUTPUT
          echo "Configured for ${PROFILE} scan profile with ${TIMEOUT} timeout"

      - name: Run Nuclei scan
        run: |
          BATCH_NUM=${{ matrix.batch }}
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          OUTPUT_JSON="nuclei_results_batch_${BATCH_NUM}_${TIMESTAMP}.json"
          OUTPUT_TXT="nuclei_results_batch_${BATCH_NUM}_${TIMESTAMP}.txt"
          
          echo "ðŸŽ¯ Starting Nuclei scan for batch ${BATCH_NUM}..."
          echo "â˜ï¸ Nuclei Cloud integration enabled with dashboard"
          
          # Debug template locations
          echo "ðŸ” Template debugging:"
          for template_dir in ~/nuclei-templates /home/runner/nuclei-templates; do
            if [ -d "$template_dir" ]; then
              TEMPLATE_COUNT=$(find "$template_dir" -name "*.yaml" -o -name "*.yml" 2>/dev/null | wc -l)
              echo "   ðŸ“ $template_dir: $TEMPLATE_COUNT templates"
              ls -la "$template_dir" | head -3
            else
              echo "   âŒ $template_dir: Not found"
            fi
          done
          
          echo ""
          echo "ðŸ“Š Scan parameters:"
          echo "   Templates: ${{ steps.scan-config.outputs.templates }}"
          echo "   Severity: ${{ steps.scan-config.outputs.severity }}"
          echo "   Rate limit: ${{ steps.scan-config.outputs.rate_limit }}"
          echo "   Timeout: ${{ steps.scan-config.outputs.timeout }}"
          echo "   Input file: ${{ steps.prepare-batch.outputs.batch_file }}"
          echo "   Subdomains: ${{ steps.prepare-batch.outputs.subdomain_count }}"
          echo ""
          
          # Show first few subdomains being scanned
          echo "ðŸŽ¯ First 3 subdomains in batch:"
          head -3 ${{ steps.prepare-batch.outputs.batch_file }}
          echo ""
          
          # Fallback: if no templates found anywhere, download manually
          TEMPLATE_CHECK=$(echo "${{ steps.scan-config.outputs.templates }}" | xargs -n1 | head -1 | sed 's/-t //')
          if [ ! -d "$TEMPLATE_CHECK" ]; then
            echo "âš ï¸ Template directory not accessible, downloading manually..."
            mkdir -p ~/nuclei-templates
            cd ~/nuclei-templates
            curl -sL https://api.github.com/repos/projectdiscovery/nuclei-templates/tarball/main | tar xz --strip-components=1 2>/dev/null || echo "Manual download failed"
            cd -
            echo "ðŸ“¦ Manual template download attempted"
          fi
          
          # Run Nuclei scan with both JSON and text output
          nuclei \
            -l ${{ steps.prepare-batch.outputs.batch_file }} \
            ${{ steps.scan-config.outputs.templates }} \
            ${{ steps.scan-config.outputs.severity }} \
            ${{ steps.scan-config.outputs.rate_limit }} \
            ${{ steps.scan-config.outputs.timeout }} \
            -j \
            -o "${OUTPUT_JSON}" \
            -o "${OUTPUT_TXT}" \
            -stats \
            -retries 1 \
            -bulk-size 100 \
            -c 50 \
            -header "User-Agent: Mozilla/5.0 (compatible; SecurityScanner/1.0)" \
            -exclude-tags dos,intrusive,brute-force \
            -max-host-error 5 \
            -auth "${{ secrets.PROJECTDISCOVERY_API_KEY }}" \
            -dashboard \
            || echo "Scan completed with some errors (exit code: $?)"
          
          # Check if results files exist and have content
          if [ -f "${OUTPUT_JSON}" ] && [ -s "${OUTPUT_JSON}" ]; then
            echo "âœ… JSON results generated: ${OUTPUT_JSON}"
            echo "ðŸ“Š JSON results count: $(wc -l < ${OUTPUT_JSON})"
            echo "results_json=${OUTPUT_JSON}" >> $GITHUB_ENV
          else
            echo "âŒ No JSON results found for batch ${BATCH_NUM}"
            echo '[]' > "${OUTPUT_JSON}"
            echo "results_json=${OUTPUT_JSON}" >> $GITHUB_ENV
          fi
          
          if [ -f "${OUTPUT_TXT}" ] && [ -s "${OUTPUT_TXT}" ]; then
            echo "âœ… Text results generated: ${OUTPUT_TXT}"
            echo "ðŸ“Š Text results count: $(wc -l < ${OUTPUT_TXT})"
            echo "results_txt=${OUTPUT_TXT}" >> $GITHUB_ENV
          else
            echo "âŒ No text results found for batch ${BATCH_NUM}"
            echo "" > "${OUTPUT_TXT}"
            echo "results_txt=${OUTPUT_TXT}" >> $GITHUB_ENV
          fi

      - name: Generate scan summary
        run: |
          BATCH_NUM=${{ matrix.batch }}
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          SUMMARY_FILE="scan_summary_batch_${BATCH_NUM}_${TIMESTAMP}.json"
          
          # Count results by severity
          if [ -f "${{ env.results_json }}" ]; then
            CRITICAL=$(jq -r 'select(.info.severity == "critical") | .info.severity' ${{ env.results_json }} 2>/dev/null | wc -l || echo "0")
            HIGH=$(jq -r 'select(.info.severity == "high") | .info.severity' ${{ env.results_json }} 2>/dev/null | wc -l || echo "0")
            MEDIUM=$(jq -r 'select(.info.severity == "medium") | .info.severity' ${{ env.results_json }} 2>/dev/null | wc -l || echo "0")
            LOW=$(jq -r 'select(.info.severity == "low") | .info.severity' ${{ env.results_json }} 2>/dev/null | wc -l || echo "0")
            INFO=$(jq -r 'select(.info.severity == "info") | .info.severity' ${{ env.results_json }} 2>/dev/null | wc -l || echo "0")
            TOTAL=$(wc -l < ${{ env.results_json }} 2>/dev/null || echo "0")
          else
            CRITICAL=0; HIGH=0; MEDIUM=0; LOW=0; INFO=0; TOTAL=0
          fi
          
          # Create summary JSON
          cat > "${SUMMARY_FILE}" << EOF
          {
            "batch_number": ${BATCH_NUM},
            "scan_timestamp": "${TIMESTAMP}",
            "subdomains_scanned": ${{ steps.prepare-batch.outputs.subdomain_count }},
            "scan_profile": "${{ github.event.inputs.scan_profile || 'full' }}",
            "results_summary": {
              "total_findings": ${TOTAL},
              "critical": ${CRITICAL},
              "high": ${HIGH},
              "medium": ${MEDIUM},
              "low": ${LOW},
              "info": ${INFO}
            },
            "scan_metadata": {
              "nuclei_version": "${{ env.NUCLEI_VERSION }}",
              "workflow_run_id": "${{ github.run_id }}",
              "workflow_run_number": "${{ github.run_number }}"
            }
          }
          EOF
          
          echo "summary_file=${SUMMARY_FILE}" >> $GITHUB_ENV
          echo "Scan summary generated for batch ${BATCH_NUM}"

      - name: Setup GPG for encryption
        run: |
          # Import GPG keys (same method as decryption)
          echo "${{ secrets.GPG_PRIVATE_KEY }}" | gpg --batch --import
          echo "${{ secrets.GPG_PUBLIC_KEY }}" | gpg --batch --import
          
          # Verify GPG setup
          gpg --list-secret-keys --keyid-format LONG
          echo "âœ… GPG keys imported successfully"

      - name: Encrypt scan results
        run: |
          BATCH_NUM=${{ matrix.batch }}
          
          # Encrypt JSON results file
          if [ -f "${{ env.results_json }}" ]; then
            gpg --batch --yes --trust-model always \
                --recipient "${{ secrets.GPG_KEY_ID }}" \
                --encrypt --armor \
                --output "${{ env.results_json }}.gpg" \
                "${{ env.results_json }}"
            echo "JSON results encrypted: ${{ env.results_json }}.gpg"
          fi
          
          # Encrypt text results file
          if [ -f "${{ env.results_txt }}" ]; then
            gpg --batch --yes --trust-model always \
                --recipient "${{ secrets.GPG_KEY_ID }}" \
                --encrypt --armor \
                --output "${{ env.results_txt }}.gpg" \
                "${{ env.results_txt }}"
            echo "Text results encrypted: ${{ env.results_txt }}.gpg"
          fi
          
          # Encrypt summary file
          if [ -f "${{ env.summary_file }}" ]; then
            gpg --batch --yes --trust-model always \
                --recipient "${{ secrets.GPG_KEY_ID }}" \
                --encrypt --armor \
                --output "${{ env.summary_file }}.gpg" \
                "${{ env.summary_file }}"
            echo "Summary encrypted: ${{ env.summary_file }}.gpg"
          fi
          
          # Clean up unencrypted files
          rm -f "${{ env.results_json }}" "${{ env.results_txt }}" "${{ env.summary_file }}"

      - name: Setup results branch
        run: |
          # Configure git
          git config --global user.name "Nuclei Scanner Bot"
          git config --global user.email "nuclei-scanner@github-actions.bot"
          
          # Set up authentication
          git remote set-url origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git
          
          # Create results branch if it doesn't exist
          git fetch origin ${{ env.RESULTS_BRANCH }} || git checkout -b ${{ env.RESULTS_BRANCH }}
          git checkout ${{ env.RESULTS_BRANCH }} || git checkout -b ${{ env.RESULTS_BRANCH }}
          
          # Create output directory structure
          mkdir -p output/$(date +%Y/%m/%d)
          mkdir -p output/latest

      - name: Store encrypted results in repo
        run: |
          BATCH_NUM=${{ matrix.batch }}
          DATE_DIR="output/$(date +%Y/%m/%d)"
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          
          # Move encrypted files to organized directory structure
          for file in nuclei_results_batch_${BATCH_NUM}_*.json.gpg; do
            if [ -f "$file" ]; then
              mv "$file" "${DATE_DIR}/nuclei_results_batch_${BATCH_NUM}_${TIMESTAMP}.json.gpg"
              echo "Moved JSON results file: $file"
            fi
          done
          
          for file in nuclei_results_batch_${BATCH_NUM}_*.txt.gpg; do
            if [ -f "$file" ]; then
              mv "$file" "${DATE_DIR}/nuclei_results_batch_${BATCH_NUM}_${TIMESTAMP}.txt.gpg"
              echo "Moved text results file: $file"
            fi
          done
          
          for file in scan_summary_batch_${BATCH_NUM}_*.json.gpg; do
            if [ -f "$file" ]; then
              mv "$file" "${DATE_DIR}/scan_summary_batch_${BATCH_NUM}_${TIMESTAMP}.json.gpg"
              echo "Moved summary file: $file"
            fi
          done
          
          # Also copy to latest directory for easy access
          if [ -f "${DATE_DIR}/nuclei_results_batch_${BATCH_NUM}_${TIMESTAMP}.json.gpg" ]; then
            cp "${DATE_DIR}/nuclei_results_batch_${BATCH_NUM}_${TIMESTAMP}.json.gpg" "output/latest/nuclei_results_batch_${BATCH_NUM}_latest.json.gpg"
          fi
          
          if [ -f "${DATE_DIR}/nuclei_results_batch_${BATCH_NUM}_${TIMESTAMP}.txt.gpg" ]; then
            cp "${DATE_DIR}/nuclei_results_batch_${BATCH_NUM}_${TIMESTAMP}.txt.gpg" "output/latest/nuclei_results_batch_${BATCH_NUM}_latest.txt.gpg"
          fi
          
          if [ -f "${DATE_DIR}/scan_summary_batch_${BATCH_NUM}_${TIMESTAMP}.json.gpg" ]; then
            cp "${DATE_DIR}/scan_summary_batch_${BATCH_NUM}_${TIMESTAMP}.json.gpg" "output/latest/scan_summary_batch_${BATCH_NUM}_latest.json.gpg"
          fi

      - name: Commit and push results
        run: |
          BATCH_NUM=${{ matrix.batch }}
          
          # Add files to git
          git add output/
          
          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No new results to commit for batch ${{ matrix.batch }}"
          else
            # Commit with detailed message
            FINDINGS_COUNT="0"
            if [ -f "output/latest/scan_summary_batch_${BATCH_NUM}_latest.json.gpg" ]; then
              # Try to get findings count from encrypted summary (will show 0 if can't decrypt)
              TEMP_SUMMARY=$(mktemp)
              if gpg --batch --yes --quiet --trust-model always --decrypt "output/latest/scan_summary_batch_${BATCH_NUM}_latest.json.gpg" > "$TEMP_SUMMARY" 2>/dev/null; then
                FINDINGS_COUNT=$(jq -r '.results_summary.total_findings // 0' "$TEMP_SUMMARY" 2>/dev/null || echo "0")
              fi
              rm -f "$TEMP_SUMMARY"
            fi
            
            git commit -m "ðŸŽ¯ Batch ${{ matrix.batch }} scan results - ${FINDINGS_COUNT} findings
            
            - Batch: ${{ matrix.batch }}
            - Timestamp: $(date -u '+%Y-%m-%d %H:%M:%S UTC')
            - Workflow: ${{ github.workflow }}
            - Run ID: ${{ github.run_id }}
            - Scan Profile: ${{ github.event.inputs.scan_profile || 'full' }}
            - Findings: ${FINDINGS_COUNT}"
            
            # Push with retry logic
            for i in {1..3}; do
              if git push origin ${{ env.RESULTS_BRANCH }}; then
                echo "Successfully pushed batch ${{ matrix.batch }} results (attempt $i)"
                break
              else
                echo "Push failed for batch ${{ matrix.batch }}, attempt $i/3"
                if [ $i -eq 3 ]; then
                  echo "Failed to push after 3 attempts"
                  exit 1
                fi
                sleep $((i * 10))  # Exponential backoff
                git pull --rebase origin ${{ env.RESULTS_BRANCH }} || true
              fi
            done
          fi

      - name: Cleanup batch files
        run: |
          rm -f batch_${{ matrix.batch }}.txt
          rm -f subdomains/all-subdomains.txt  # Remove decrypted subdomain file
          rm -f *.json
          echo "Cleanup completed for batch ${{ matrix.batch }}"

  # Job to consolidate all batch results into single files
  consolidate-all-results:
    needs: [prepare-batches, nuclei-scan]
    if: always() && needs.prepare-batches.result == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Checkout results branch
        run: |
          git fetch origin ${{ env.RESULTS_BRANCH }} || echo "Results branch doesn't exist yet"
          git checkout ${{ env.RESULTS_BRANCH }} || echo "No results branch to checkout"

      - name: Setup GPG for decryption
        run: |
          echo "${{ secrets.GPG_PRIVATE_KEY }}" | gpg --batch --import
          echo "${{ secrets.GPG_PUBLIC_KEY }}" | gpg --batch --import

      - name: Generate consolidated report
        run: |
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          REPORT_FILE="consolidated_report_${TIMESTAMP}.json"
          
          # Initialize report structure
          cat > "${REPORT_FILE}" << EOF
          {
            "scan_metadata": {
              "timestamp": "${TIMESTAMP}",
              "workflow_run_id": "${{ github.run_id }}",
              "total_batches_processed": $(ls encrypted-results/*summary*.gpg 2>/dev/null | wc -l),
              "scan_profile": "${{ github.event.inputs.scan_profile || 'full' }}"
            },
            "batch_summaries": [],
            "overall_summary": {
              "total_findings": 0,
              "critical": 0,
              "high": 0,
              "medium": 0,
              "low": 0,
              "info": 0,
              "total_subdomains_scanned": 0
            }
          }
          EOF
          
          # Process each summary file from latest results
          TOTAL_FINDINGS=0
          TOTAL_CRITICAL=0
          TOTAL_HIGH=0
          TOTAL_MEDIUM=0
          TOTAL_LOW=0
          TOTAL_INFO=0
          TOTAL_SUBDOMAINS=0
          
          if [ -d "output/latest" ]; then
            for summary_file in output/latest/*summary*.gpg; do
            if [ -f "$summary_file" ]; then
              # Decrypt summary
              DECRYPTED_SUMMARY=$(mktemp)
              gpg --batch --yes --quiet --trust-model always --decrypt "$summary_file" > "$DECRYPTED_SUMMARY" 2>/dev/null
              
              if [ -s "$DECRYPTED_SUMMARY" ]; then
                # Extract values from summary
                BATCH_FINDINGS=$(jq -r '.results_summary.total_findings' "$DECRYPTED_SUMMARY" 2>/dev/null || echo "0")
                BATCH_CRITICAL=$(jq -r '.results_summary.critical' "$DECRYPTED_SUMMARY" 2>/dev/null || echo "0")
                BATCH_HIGH=$(jq -r '.results_summary.high' "$DECRYPTED_SUMMARY" 2>/dev/null || echo "0")
                BATCH_MEDIUM=$(jq -r '.results_summary.medium' "$DECRYPTED_SUMMARY" 2>/dev/null || echo "0")
                BATCH_LOW=$(jq -r '.results_summary.low' "$DECRYPTED_SUMMARY" 2>/dev/null || echo "0")
                BATCH_INFO=$(jq -r '.results_summary.info' "$DECRYPTED_SUMMARY" 2>/dev/null || echo "0")
                BATCH_SUBDOMAINS=$(jq -r '.subdomains_scanned' "$DECRYPTED_SUMMARY" 2>/dev/null || echo "0")
                
                # Add to totals
                TOTAL_FINDINGS=$((TOTAL_FINDINGS + BATCH_FINDINGS))
                TOTAL_CRITICAL=$((TOTAL_CRITICAL + BATCH_CRITICAL))
                TOTAL_HIGH=$((TOTAL_HIGH + BATCH_HIGH))
                TOTAL_MEDIUM=$((TOTAL_MEDIUM + BATCH_MEDIUM))
                TOTAL_LOW=$((TOTAL_LOW + BATCH_LOW))
                TOTAL_INFO=$((TOTAL_INFO + BATCH_INFO))
                TOTAL_SUBDOMAINS=$((TOTAL_SUBDOMAINS + BATCH_SUBDOMAINS))
                
                # Add to batch summaries array
                TEMP_REPORT=$(mktemp)
                jq --slurpfile batch "$DECRYPTED_SUMMARY" '.batch_summaries += $batch' "$REPORT_FILE" > "$TEMP_REPORT"
                mv "$TEMP_REPORT" "$REPORT_FILE"
              fi
              
              rm -f "$DECRYPTED_SUMMARY"
            fi
            done
          else
            echo "No latest results directory found"
          fi
          
          # Update overall summary
          TEMP_REPORT=$(mktemp)
          jq --argjson total_findings "$TOTAL_FINDINGS" \
             --argjson critical "$TOTAL_CRITICAL" \
             --argjson high "$TOTAL_HIGH" \
             --argjson medium "$TOTAL_MEDIUM" \
             --argjson low "$TOTAL_LOW" \
             --argjson info "$TOTAL_INFO" \
             --argjson subdomains "$TOTAL_SUBDOMAINS" \
             '.overall_summary.total_findings = $total_findings |
              .overall_summary.critical = $critical |
              .overall_summary.high = $high |
              .overall_summary.medium = $medium |
              .overall_summary.low = $low |
              .overall_summary.info = $info |
              .overall_summary.total_subdomains_scanned = $subdomains' \
             "$REPORT_FILE" > "$TEMP_REPORT"
          mv "$TEMP_REPORT" "$REPORT_FILE"
          
          echo "report_file=${REPORT_FILE}" >> $GITHUB_ENV
          echo "Generated consolidated report with ${TOTAL_FINDINGS} total findings across ${TOTAL_SUBDOMAINS} subdomains"

      - name: Encrypt consolidated report
        run: |
          if [ -f "${{ env.report_file }}" ]; then
            gpg --batch --yes --trust-model always \
                --recipient "${{ secrets.GPG_KEY_ID }}" \
                --encrypt --armor \
                --output "${{ env.report_file }}.gpg" \
                "${{ env.report_file }}"
            
            rm -f "${{ env.report_file }}"
            echo "âœ… Consolidated report encrypted"
          fi

      - name: Store consolidated report in repo
        run: |
          # Configure git
          git config --global user.name "Nuclei Scanner Bot"
          git config --global user.email "nuclei-scanner@github-actions.bot"
          
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          DATE_DIR="output/$(date +%Y/%m/%d)"
          
          # Ensure we're on results branch
          git checkout ${{ env.RESULTS_BRANCH }} || git checkout -b ${{ env.RESULTS_BRANCH }}
          
          # Create directories
          mkdir -p "${DATE_DIR}"
          mkdir -p "output/latest"
          
          # Move consolidated report
          if [ -f "consolidated_report_*.json.gpg" ]; then
            mv consolidated_report_*.json.gpg "${DATE_DIR}/consolidated_report_${TIMESTAMP}.json.gpg"
            cp "${DATE_DIR}/consolidated_report_${TIMESTAMP}.json.gpg" "output/latest/consolidated_report_latest.json.gpg"
            
            # Add and commit
            git add output/
            git commit -m "ðŸ“Š Consolidated scan report - $(date -u '+%Y-%m-%d %H:%M:%S UTC')
            
            - Workflow: ${{ github.workflow }}
            - Run ID: ${{ github.run_id }}
            - Timestamp: ${TIMESTAMP}
            - Type: Consolidated Report"
            
            # Push with retry logic
            for i in {1..3}; do
              if git push origin ${{ env.RESULTS_BRANCH }}; then
                echo "Successfully pushed consolidated report (attempt $i)"
                break
              else
                echo "Push failed for consolidated report, attempt $i/3"
                if [ $i -eq 3 ]; then
                  echo "Failed to push after 3 attempts"
                  exit 1
                fi
                sleep $((i * 10))
                git pull --rebase origin ${{ env.RESULTS_BRANCH }} || true
              fi
            done
          fi

      - name: Create workflow summary
        run: |
          # Decrypt report for summary (without storing unencrypted version)
          TEMP_REPORT=$(mktemp)
          gpg --batch --yes --quiet --trust-model always --decrypt "${{ env.report_file }}.gpg" > "$TEMP_REPORT" 2>/dev/null
          
          if [ -s "$TEMP_REPORT" ]; then
            TOTAL_FINDINGS=$(jq -r '.overall_summary.total_findings' "$TEMP_REPORT")
            CRITICAL=$(jq -r '.overall_summary.critical' "$TEMP_REPORT")
            HIGH=$(jq -r '.overall_summary.high' "$TEMP_REPORT")
            MEDIUM=$(jq -r '.overall_summary.medium' "$TEMP_REPORT")
            LOW=$(jq -r '.overall_summary.low' "$TEMP_REPORT")
            INFO=$(jq -r '.overall_summary.info' "$TEMP_REPORT")
            SUBDOMAINS=$(jq -r '.overall_summary.total_subdomains_scanned' "$TEMP_REPORT")
            BATCHES=$(jq -r '.scan_metadata.total_batches_processed' "$TEMP_REPORT")
            
            cat >> $GITHUB_STEP_SUMMARY << EOF
          # ðŸŽ¯ Nuclei Mass Scan Results
          
          ## ðŸ“Š Scan Overview
          - **Total Subdomains Scanned**: ${SUBDOMAINS}
          - **Batches Processed**: ${BATCHES}
          - **Total Findings**: ${TOTAL_FINDINGS}
          - **Dashboard**: [View in Nuclei Cloud](https://cloud.nuclei.sh) (if API key configured)
          
          ## ðŸš¨ Findings by Severity
          | Severity | Count |
          |----------|-------|
          | Critical | ${CRITICAL} |
          | High     | ${HIGH} |
          | Medium   | ${MEDIUM} |
          | Low      | ${LOW} |
          | Info     | ${INFO} |
          
          ## ðŸ”’ Security
          All results have been encrypted with GPG and are available as artigitfacts.
          
          ## ðŸ“ Artifacts
          - \`consolidated-encrypted-report\`: Complete scan report (encrypted)
          - \`encrypted-results-batch-*\`: Individual batch results (encrypted)
          
          **Note**: Use your private GPG key to decrypt the results locally.
          EOF
          else
            echo "âš ï¸ Could not generate detailed summary - report decryption failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          rm -f "$TEMP_REPORT"
